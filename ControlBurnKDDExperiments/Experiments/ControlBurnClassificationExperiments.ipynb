{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Required Packages\n",
    "import sklearn\n",
    "import statistics\n",
    "import scipy as sc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import cvxpy as cp\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing as mp\n",
    "from multiprocessing import Pool\n",
    "import time\n",
    "import re\n",
    "import sys\n",
    "import xgboost as xgb\n",
    "import gc\n",
    "import mosek\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from pmlb import fetch_data\n",
    "from pmlb import classification_dataset_names, regression_dataset_names\n",
    "\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "pd.set_option('display.max_columns', None)\n",
    "sys.path.append('../')\n",
    "\n",
    "from IncrementalDepthBagging.IncrementalDepthBagging import IncrementalDepthBaggingClassifier_fit\n",
    "from IncrementalDepthBagging.IncrementalDepthBagging import IncrementalDepthBaggingClassifier_predict_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IncrementalDepthBagBoostClassifier_predict(xTest,log_odds_init,tree_list):\n",
    "    res = log_odds_predict(xTest,log_odds_init,tree_list)\n",
    "    return np.exp(res)/(1+np.exp(res))\n",
    "\n",
    "def log_odds_predict(xTest,log_odds_init,tree_list):\n",
    "    res = []\n",
    "    for i in tree_list:\n",
    "        depth = i.max_depth\n",
    "        pred = i.predict(xTest)\n",
    "        res.append([depth,pred])\n",
    "    res = pd.DataFrame(res,columns = ['depth','pred'])\n",
    "    res = res.groupby('depth')['pred'].apply(np.mean).reset_index()\n",
    "    res = np.sum(res['pred'].to_numpy()) + log_odds_init\n",
    "    return res\n",
    "\n",
    "\n",
    "def converge_test(sequence, threshold,length):\n",
    "    diff = np.diff(sequence)\n",
    "    if len(diff) < (length+1):\n",
    "        return False\n",
    "    else:\n",
    "        return (max(np.abs(diff[-length:])) < threshold)\n",
    "    \n",
    "def check_OOB_convergence(OOB_error_list):\n",
    "    if OOB_error_list[-1] <= 0:\n",
    "        return True\n",
    "    elif (len(OOB_error_list) < 4):\n",
    "        return False\n",
    "    elif all([x < 10**-4 for x in OOB_error_list[-3:]]):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IncrementalDepthBagBoostClassifier_OOB_EarlyStop(xTrain,yTrain, threshold,tail):\n",
    "    yTrain = pd.Series(yTrain)\n",
    "    yTrain.index = xTrain.index\n",
    "    #initialization\n",
    "    log_odds = np.log(sum(yTrain)/(len(yTrain)- sum(yTrain)))\n",
    "    prob = np.exp(log_odds)/(1+np.exp(log_odds))\n",
    "    residual = yTrain - prob\n",
    "\n",
    "    train = xTrain.copy()\n",
    "    train['yTrain'] = list(residual)\n",
    "    features = xTrain.columns\n",
    "    pred_train = np.zeros(len(residual))\n",
    "    tree_list = []\n",
    "    \n",
    "    OOB_error_list = []\n",
    "    OOB_converged = False\n",
    "    depth = 1\n",
    "    while OOB_converged == False:\n",
    "    \n",
    "        early_stop_pred = []\n",
    "        early_stop_train_err = []\n",
    "        converged = False\n",
    "        OOB_matrix = []\n",
    "        tree_list1 = []\n",
    "\n",
    "        if len(tree_list) > 0:\n",
    "            current_pred = log_odds_predict(xTrain,log_odds,tree_list)\n",
    "            xTrain['current_pred'] = current_pred\n",
    "            current_pred = xTrain['current_pred']\n",
    "            xTrain.drop('current_pred',axis = 1,inplace = True)\n",
    "        else:\n",
    "            xTrain['current_pred'] = log_odds\n",
    "            current_pred = xTrain['current_pred']\n",
    "            xTrain.drop('current_pred',axis = 1,inplace = True)\n",
    "        \n",
    "        \n",
    "        while converged == False:\n",
    "            \n",
    "            train1 = train.sample(n = len(train), replace = True)\n",
    "            OOB = train[~train.index.isin(train1.drop_duplicates().index.values)].index.values\n",
    "            OOB_row = np.repeat(False,len(xTrain))\n",
    "            OOB_row[OOB] = True\n",
    "            OOB_matrix.append(OOB_row)        \n",
    "            yTrain1 = train1['yTrain']\n",
    "            xTrain1 = train1[features]\n",
    "            tree = DecisionTreeRegressor(max_depth = depth)\n",
    "            tree.fit(xTrain1,yTrain1)\n",
    "            tree_list.append(tree)\n",
    "            tree_list1.append(tree)\n",
    "            pred = tree.predict(xTrain[features])\n",
    "            early_stop_pred.append(pred)\n",
    "            \n",
    "            temp_pred = current_pred + (np.mean(early_stop_pred,axis = 0))\n",
    "            temp_prob = np.exp(temp_pred)/(1+np.exp(temp_pred))\n",
    "        \n",
    "            early_stop_train_err.append(sklearn.metrics.roc_auc_score(yTrain,temp_prob))\n",
    "            #early_stop_train_err.append(sklearn.metrics.mean_squared_error(train['yTrain'],(np.mean(early_stop_pred,axis = 0))))\n",
    "            converged = converge_test(early_stop_train_err,threshold,tail)\n",
    "            pred_train = pred_train + np.mean(early_stop_pred,axis = 0)\n",
    "            if converged == False:\n",
    "                pred_train = pred_train - np.mean(early_stop_pred,axis = 0)\n",
    "                \n",
    "        ### compute OOB\n",
    "        indicators = pd.DataFrame(OOB_matrix).transpose()\n",
    "        OOB_pred_list = []\n",
    "        #yTrain2 = train['yTrain'].copy()\n",
    "        yTrain2 = yTrain.copy()\n",
    "        for i,row in xTrain.iterrows():\n",
    "            row = row.to_frame().transpose()\n",
    "            temp_series = indicators.iloc[i]\n",
    "            OOB_trees = list(temp_series[temp_series].index.values)\n",
    "            OOB_tree_list = list(np.array(tree_list1)[OOB_trees])\n",
    "        \n",
    "            if len(OOB_tree_list) > 0:\n",
    "                OOB_pred = []\n",
    "                for tree_temp in OOB_tree_list:\n",
    "                    OOB_pred.append(tree_temp.predict(row)[0])\n",
    "                OOB_pred_list.append(np.mean(OOB_pred))\n",
    "            else:\n",
    "                yTrain2 = yTrain2.drop(i)\n",
    "                current_pred = current_pred.drop(i)\n",
    "        \n",
    "        next_pred = np.array(current_pred) + np.array(OOB_pred_list)\n",
    "        \n",
    "        current_prob =  np.exp(current_pred)/(1+np.exp(current_pred))\n",
    "        next_prob =  np.exp(next_pred)/(1+np.exp(next_pred))\n",
    "        \n",
    "        current_err = 1 - sklearn.metrics.roc_auc_score(yTrain2,current_prob)\n",
    "        next_err = 1 - sklearn.metrics.roc_auc_score(yTrain2,next_prob)\n",
    "        \n",
    "        print(1-current_err,1-next_err, depth)\n",
    "        OOB_error_list.append(current_err-next_err)\n",
    "        \n",
    "        all_pred = log_odds_predict(xTrain,log_odds,tree_list)\n",
    "        all_prob = np.exp(all_pred)/(1+np.exp(all_pred))\n",
    "        train['yTrain'] = yTrain-all_prob\n",
    "        OOB_converged = check_OOB_convergence(OOB_error_list)\n",
    "        depth = depth + 1\n",
    "        \n",
    "    return tree_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OptimizationStepClassification(xTrain,yTrain,tree_list,lambd, optimization_type = 'penalized'):\n",
    "    pred = []\n",
    "    ind = []\n",
    "    \n",
    "    yTrain = pd.Series(yTrain)\n",
    "    yTrain.index = xTrain.index\n",
    "    #initialization\n",
    "    log_odds = np.log(sum(yTrain)/(len(yTrain)- sum(yTrain)))\n",
    "    \n",
    "    for tree in tree_list:\n",
    "        pred.append(tree.predict(xTrain))\n",
    "        ind.append([int(x > 0) for x in tree.feature_importances_])  \n",
    "\n",
    "    pred = np.transpose(pred)\n",
    "    ind = np.transpose(ind)\n",
    "    \n",
    "    w = cp.Variable(len(tree_list),nonneg=True)\n",
    "    constraints = []\n",
    "    \n",
    "    \n",
    "    if optimization_type == 'penalized':\n",
    "        loss = -cp.sum( cp.multiply(yTrain, pred@ w ) - cp.logistic(pred @ w) )\n",
    "        objective = (1/len(yTrain))*loss + lambd*cp.norm(cp.matmul(ind,w),1)\n",
    "\n",
    "\n",
    "    if optimization_type == 'constrained':\n",
    "        objective = -cp.sum(cp.multiply(yTrain, pred@ w) - cp.logistic(pred @ w))\n",
    "        constraints = [cp.norm(cp.matmul(ind,w),1)<= lambd]\n",
    "\n",
    "    prob = cp.Problem(cp.Minimize(objective),constraints)\n",
    "    prob.solve(solver = cp.MOSEK,mosek_params = {mosek.dparam.optimizer_max_time: 10000.0} )\n",
    "    weights = np.asarray(w.value)\n",
    "    weights[np.abs(weights) < 10**-3] = 0 \n",
    "    return weights\n",
    "\n",
    "def ControlBurnClassifier_predict(xTest, log_odds_init, tree_list, weights):\n",
    "    res = []\n",
    "    for i in range(0,len(tree_list)):\n",
    "        res.append(weights[i]*tree_list[i].predict(xTest))\n",
    "    pred = log_odds_init + np.sum(res,axis = 0)\n",
    "    prob = np.exp(pred)/(1+np.exp(pred))\n",
    "    return prob\n",
    "\n",
    "def ControlBurnClassifier_select_features(xTest, tree_list,weights):\n",
    "    imp = []\n",
    "    for i in range(0,len(weights)):\n",
    "        imp.append(weights[i]*tree_list[i].feature_importances_)\n",
    "    imp1 = np.sum(imp, axis = 0)\n",
    "    return imp1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_classifiers(xTrain,yTrain,xTest,yTest, num_features, num_trees):\n",
    "    model = RandomForestClassifier(n_estimators = num_trees)\n",
    "    rf = model.fit(xTrain,yTrain)\n",
    "    imp = pd.DataFrame(np.column_stack((xTrain.columns,rf.feature_importances_)),columns = ['features','scores'])\n",
    "    imp = imp.sort_values('scores',ascending = False)\n",
    "    to_use = imp.head(num_features)['features'].values\n",
    "    rf1 = model.fit(xTrain[to_use],yTrain)\n",
    "    pred = rf1.predict_proba(xTest[to_use])[:,1]\n",
    "    return sklearn.metrics.roc_auc_score(yTest,pred)\n",
    "\n",
    "def evaluate_classification_experiment(xTrain,yTrain,xTest,yTest,lambd,tree_list,form):\n",
    "    weights = OptimizationStepClassification(xTrain, yTrain,tree_list, lambd,form)\n",
    "    imp1 = ControlBurnClassifier_select_features(xTest, tree_list,weights)\n",
    "    \n",
    "    if sum(imp1>0) == 0:\n",
    "        return [.5,5,0]\n",
    "    \n",
    "    rf = RandomForestClassifier(n_estimators = 100).fit(xTrain[xTrain.columns[imp1 > 0]],yTrain)\n",
    "    pred_polish = rf.predict_proba(xTest[xTrain.columns[imp1 > 0]])[:,1]\n",
    "    acc_polish = sklearn.metrics.roc_auc_score(yTest,pred_polish)\n",
    "\n",
    "    importances = pd.DataFrame(np.column_stack((xTrain.columns,imp1)),columns = ['features','scores'])\n",
    "    importances = importances.sort_values('scores',ascending = False)\n",
    "    num_features = np.sum(importances['scores'] != 0)\n",
    "    \n",
    "    acc_base = baseline_classifiers(xTrain,yTrain,xTest,yTest, np.sum(imp1>0), len(tree_list))\n",
    "\n",
    "    return [acc_polish,acc_base,num_features]\n",
    "\n",
    "def classification_bisection_lambd(xTrain,yTrain,xTest,yTest,tree_list,form,lambd,count_limit,feature_to_find):\n",
    "    counter = 0\n",
    "    to_find = 0\n",
    "    total_results = []\n",
    "    while to_find <= feature_to_find:\n",
    "        results = evaluate_classification_experiment(xTrain,yTrain,xTest,yTest,lambd,tree_list,form)\n",
    "        nfeat = results[2]\n",
    "        print(to_find,nfeat,lambd)\n",
    "\n",
    "        if nfeat == to_find:\n",
    "            to_find = to_find + 1\n",
    "\n",
    "        elif counter > count_limit:\n",
    "            to_find = to_find + 1\n",
    "            counter = 0\n",
    "\n",
    "        elif nfeat < to_find:\n",
    "            lambd = lambd/2\n",
    "\n",
    "        elif nfeat > to_find:\n",
    "            lambd = lambd + lambd/2\n",
    "\n",
    "        counter = counter + 1\n",
    "\n",
    "        total_results.append(results)\n",
    "    return total_results\n",
    "\n",
    "def full_model(X,y):\n",
    "    kf = KFold(n_splits=5)\n",
    "    kf.get_n_splits(X)\n",
    "    results = []\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        xTrain, xTest = X.iloc[train_index], X.iloc[test_index]\n",
    "        yTrain, yTest = y.iloc[train_index], y.iloc[test_index]\n",
    "        features = xTrain.columns\n",
    "        xTrain = preprocessing.scale(xTrain)\n",
    "        xTrain = pd.DataFrame(xTrain,columns = features)\n",
    "        xTest = preprocessing.scale(xTest)\n",
    "        xTest = pd.DataFrame(xTest,columns = features)\n",
    "        yTest = pd.Series(yTest)\n",
    "        yTrain = pd.Series(yTrain)\n",
    "        yTest.index = xTest.index\n",
    "        yTrain.index = xTrain.index\n",
    "        pred = RandomForestClassifier(n_estimators = 1000, max_features = 'sqrt').fit(xTrain,yTrain).predict_proba(xTest)[:,1]\n",
    "        results.append(sklearn.metrics.roc_auc_score(yTest,pred))\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_audit():\n",
    "    audit_risk = pd.read_csv(\"data/audit_risk.csv\")\n",
    "    trial = pd.read_csv(\"data/trial.csv\")\n",
    "    trial.columns = ['Sector_score','LOCATION_ID', 'PARA_A', 'Score_A', 'PARA_B',\n",
    "           'Score_B',  'TOTAL', 'numbers', 'Marks',\n",
    "           'Money_Value', 'MONEY_Marks', 'District',\n",
    "           'Loss', 'LOSS_SCORE', 'History', 'History_score', 'Score', 'Risk_trial' ]\n",
    "    trial['Score_A'] = trial['Score_A']/10\n",
    "    trial['Score_B'] = trial['Score_B']/10\n",
    "    merged_df = pd.merge(audit_risk, trial, how='outer', on = ['History', 'LOCATION_ID', 'Money_Value', 'PARA_A', 'PARA_B',\n",
    "           'Score', 'Score_A', 'Score_B', 'Sector_score', 'TOTAL', 'numbers'])\n",
    "\n",
    "    df = merged_df.drop(['Risk_trial'], axis = 1)\n",
    "    df['Money_Value'] = df['Money_Value'].fillna(df['Money_Value'].median())\n",
    "    df = df.drop(['Detection_Risk', 'Risk_F'], axis = 1) \n",
    "    df = df[(df.LOCATION_ID != 'LOHARU')]\n",
    "    df = df[(df.LOCATION_ID != 'NUH')]\n",
    "    df = df[(df.LOCATION_ID != 'SAFIDON')]\n",
    "    df = df.astype(float)\n",
    "    df = df.drop_duplicates(keep = 'first')\n",
    "    class_df = df.drop([\"Audit_Risk\",'Inherent_Risk','Score','TOTAL'], axis = 1)\n",
    "    y = class_df[\"Risk\"]    \n",
    "    X = class_df.drop([\"Risk\"], axis = 1)\n",
    "\n",
    "    return X,y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load Data\n",
    "\n",
    "# ###########################################################\n",
    "# #PMLB\n",
    "\n",
    "# dataset = 'twonorm'\n",
    "\n",
    "# data = fetch_data(dataset)\n",
    "# data = data.sample(len(data))\n",
    "# y = data['target']\n",
    "# X = data.drop('target',axis = 1)\n",
    "\n",
    "\n",
    "# ###########################################################\n",
    "# #OpenML\n",
    "\n",
    "# dataset = 'lung-cancer'\n",
    "# from sklearn.datasets import fetch_openml\n",
    "# data = fetch_openml(name=dataset)\n",
    "# #X = pd.DataFrame(data.data,columns = data.feature_names)\n",
    "# X = pd.DataFrame.sparse.from_spmatrix(data.data, columns = data.feature_names).sparse.to_dense()\n",
    "# y = pd.Series(data.target).map({-1:0,1:1})\n",
    "\n",
    "\n",
    "\n",
    "###########################################################\n",
    "print(dataset)\n",
    "print(len(X),len(X.columns))\n",
    "kf = KFold(n_splits=5)\n",
    "kf.get_n_splits(X)\n",
    "\n",
    "final_result_bagboost = pd.DataFrame(None)\n",
    "final_result_bag = pd.DataFrame(None)\n",
    "folds_data = []\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    xTrain, xTest = X.iloc[train_index], X.iloc[test_index]\n",
    "    yTrain, yTest = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    features = xTrain.columns\n",
    "    xTrain = preprocessing.scale(xTrain,with_mean=False)\n",
    "    xTrain = pd.DataFrame(xTrain,columns = features)\n",
    "    xTest = preprocessing.scale(xTest,with_mean=False)\n",
    "    xTest = pd.DataFrame(xTest,columns = features)\n",
    "    yTest = pd.Series(yTest)\n",
    "    yTrain = pd.Series(yTrain)\n",
    "    yTest.index = xTest.index\n",
    "    yTrain.index = xTrain.index\n",
    "    \n",
    "    folds_data.append([xTrain,xTest,yTrain,yTest])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "import ray\n",
    "import time\n",
    "\n",
    "# Start Ray\n",
    "ray.shutdown()\n",
    "ray.init()\n",
    "\n",
    "@ray.remote\n",
    "def parallel_wrapper(arg):\n",
    "    xTrain = arg[0]\n",
    "    xTest = arg[1]\n",
    "    yTrain = arg[2]\n",
    "    yTest = arg[3]\n",
    "    \n",
    "    features_to_find = min(len(X.columns),10)\n",
    "    \n",
    "    tree_list = IncrementalDepthBagBoostClassifier_OOB_EarlyStop(xTrain,yTrain,10**-3,5)\n",
    "    res = classification_bisection_lambd(xTrain,yTrain,xTest,yTest,tree_list,'penalized',10,8,features_to_find)\n",
    "    res = pd.DataFrame(res, columns = ['polish','base','nonzero'])\n",
    "    \n",
    "    return res\n",
    "\n",
    "result_ids = []\n",
    "for i in folds_data:\n",
    "    result_ids.append(parallel_wrapper.remote(i))\n",
    "    \n",
    "\n",
    "results = ray.get(result_ids)  \n",
    "ray.shutdown()\n",
    "\n",
    "final_result_bagboost = pd.DataFrame(None)\n",
    "\n",
    "for r in results:\n",
    "    final_result_bagboost = final_result_bagboost.append(r)\n",
    "\n",
    "    \n",
    "final_result_agg = final_result_bagboost.groupby('nonzero').agg(['mean','std']).reset_index()\n",
    "final_result_agg = final_result_agg[final_result_agg['nonzero'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "full = full_model(X,y)\n",
    "final_result_agg['full_mean'] = np.mean(full)\n",
    "final_result_agg['full_std']= np.std(full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(final_result_agg['nonzero'],final_result_agg['base']['mean'],label = 'baseline', color = 'blue')\n",
    "plt.scatter(final_result_agg['nonzero'],final_result_agg['base']['mean'],color = 'blue')\n",
    "plt.errorbar(final_result_agg['nonzero'],final_result_agg['base']['mean'],yerr = final_result_agg['base']['std'],color = 'blue')\n",
    "\n",
    "\n",
    "plt.plot(final_result_agg['nonzero'],final_result_agg['polish']['mean'],label = 'polished',color = 'green')\n",
    "plt.scatter(final_result_agg['nonzero'],final_result_agg['polish']['mean'], color = 'green')\n",
    "plt.errorbar(final_result_agg['nonzero'],final_result_agg['polish']['mean'],yerr = final_result_agg['polish']['std'], color = 'green')\n",
    "plt.xlim(0,10)\n",
    "#plt.axhline(final_result_agg['full_mean'].values[0],label = 'full RF model')\n",
    "plt.legend()\n",
    "plt.title(dataset+ ' bagboost')\n",
    "plt.ylabel('ROC AUC')\n",
    "plt.xlabel('Features Selected')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result_agg.to_csv('../Results/'+dataset+'_bagboost_5fold.csv',index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "dataset = 'pima'\n",
    "\n",
    "final_result_agg = pd.read_csv('bagboostresults/'+dataset+'_bagboost_5fold.csv')\n",
    "final_result_agg.drop(0,axis = 0,inplace = True)\n",
    "final_result_agg.columns = ['nonzero','polish_mean','polish_std','base_mean','base_std','full_mean','full_std']\n",
    "final_result_agg = final_result_agg.astype(float)\n",
    "final_result_agg = final_result_agg[final_result_agg['nonzero'] < 10]\n",
    "                                    \n",
    "                                    \n",
    "                                    \n",
    "plt.plot(final_result_agg['nonzero'],final_result_agg['base_mean'],label = 'baseline', color = 'blue')\n",
    "plt.scatter(final_result_agg['nonzero'],final_result_agg['base_mean'],color = 'blue')\n",
    "plt.errorbar(final_result_agg['nonzero'],final_result_agg['base_mean'],yerr = final_result_agg['base_std'],color = 'blue')\n",
    "\n",
    "\n",
    "plt.plot(final_result_agg['nonzero'],final_result_agg['polish_mean'],label = 'polished',color = 'green')\n",
    "plt.scatter(final_result_agg['nonzero'],final_result_agg['polish_mean'], color = 'green')\n",
    "plt.errorbar(final_result_agg['nonzero'],final_result_agg['polish_mean'],yerr = final_result_agg['polish_std'], color = 'green')\n",
    "\n",
    "plt.axhline(final_result_agg['full_mean'].values[0],label = 'full RF model')\n",
    "plt.legend()\n",
    "plt.title(dataset+ ' bagboost')\n",
    "plt.ylabel('ROC AUC')\n",
    "plt.xlabel('Features Selected')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
