{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83c3670d",
   "metadata": {},
   "source": [
    "## Data Processing\n",
    "\n",
    "Load the California housing dataset:\n",
    "https://www.kaggle.com/camnugent/california-housing-prices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a32dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "data = datasets.fetch_california_housing()\n",
    "X = pd.DataFrame(data.data, columns = data.feature_names)\n",
    "y = data.target\n",
    "y = pd.Series(y)\n",
    "y.index = X.index\n",
    "print(str(len(X)) + ' rows')\n",
    "print(str(len(X.columns)) + ' columns')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb1e5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f7a59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "xTrainScaler = preprocessing.StandardScaler()\n",
    "xTrain = xTrainScaler.fit_transform(xTrain)\n",
    "xTrain = pd.DataFrame(xTrain,columns = X.columns)\n",
    "xTest = preprocessing.StandardScaler().fit_transform(xTest)\n",
    "xTest = pd.DataFrame(xTest,columns = X.columns)\n",
    "yTrain = preprocessing.StandardScaler().fit_transform(yTrain.values.reshape(-1, 1))\n",
    "yTest = preprocessing.StandardScaler().fit_transform(yTest.values.reshape(-1, 1))\n",
    "yTrain = pd.Series(yTrain.flatten())\n",
    "yTrain.index = xTrain.index\n",
    "yTest = pd.Series(yTest.flatten())\n",
    "yTest.index = xTest.index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845e0134",
   "metadata": {},
   "source": [
    "## Install ControlBurn package\n",
    "\n",
    "https://pypi.org/project/ControlBurn/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fa3c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ControlBurn==0.0.9\n",
    "from ControlBurn.ControlBurn import ControlBurnRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fdf363",
   "metadata": {},
   "source": [
    "## Fit a ControlBurnRegressor\n",
    "\n",
    "Build forest via double bag-boosting and select features using lasso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d35fa12",
   "metadata": {},
   "outputs": [],
   "source": [
    "cb = ControlBurnRegressor(build_forest_method = 'doublebagboost', alpha = 0.02)\n",
    "cb.fit(xTrain,yTrain)\n",
    "\n",
    "print('Number of trees grown: ' + str(len(cb.forest)))\n",
    "print('Number of trees selected: ' + str(len(cb.subforest)))\n",
    "print('Features selected ' + str(cb.features_selected_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6afce69",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = cb.predict(xTest)\n",
    "print('MSE of polished model: ' + str(mean_squared_error(yTest,pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a716c8",
   "metadata": {},
   "source": [
    "## Interpretability Plots\n",
    "Print a list of features used in each tree in the selected subforest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c372e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_list = cb.subforest\n",
    "cols = X.columns\n",
    "for tree in tree_list:\n",
    "    print(cols[tree.feature_importances_ > 0].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33950fcc",
   "metadata": {},
   "source": [
    "### Single Feature Trees\n",
    "For single feature trees, plot the contribution to the prediction as a function of the feature value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f93cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot for single feature f(x) plots\n",
    "sub_weights = cb.weights[cb.weights>0]\n",
    "for feat in cols:\n",
    "    loc = 0\n",
    "    pred_all = []\n",
    "    for tree in tree_list:\n",
    "        if ((feat in cols[tree.feature_importances_>0]) & (len(cols[tree.feature_importances_>0]) == 1)) :\n",
    "            x_temp = pd.DataFrame(np.linspace(-1,1,1000),columns = [feat])\n",
    "            \n",
    "            for i in cols:\n",
    "                if i != feat:\n",
    "                    x_temp[i] = 0\n",
    "            x_temp = x_temp[X.columns]\n",
    "        \n",
    "            pred = tree.predict(x_temp)\n",
    "            pred_all.append(pred*sub_weights[loc])\n",
    "        \n",
    "        loc = loc+1\n",
    "    pred_all = np.sum(pred_all,axis = 0)\n",
    "    plt.plot(np.linspace(-1,1,1000),pred_all)\n",
    "    plt.xlabel(feat)\n",
    "    plt.ylabel('Contribution to Prediction')\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c586791",
   "metadata": {},
   "source": [
    "### Two Feature Trees (pairwise feature interactions)\n",
    "\n",
    "The below heat map shows the frequency of which features appear together. This is useful for detecting feature interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f7013e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import seaborn as sns\n",
    "from itertools import combinations,permutations\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "pairs = list(permutations(cols,2))\n",
    "counter = pd.DataFrame(pairs,columns = ['Feature 1','Feature 2'])\n",
    "\n",
    "counts = []\n",
    "for i in pairs:\n",
    "    n = 0\n",
    "    for tree in tree_list:\n",
    "        feats = list(cols[tree.feature_importances_>0])\n",
    "        if ((i[0] in feats) & (i[1] in feats)):\n",
    "            n = n + 1\n",
    "    counts.append(n)\n",
    "counter['count'] = counts\n",
    "counter = counter.pivot_table(index='Feature 1', columns='Feature 2', values='count')\n",
    "mask = np.zeros_like(counter, dtype='bool')\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "sns.heatmap(counter, mask = mask , cmap = 'Blues')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16877507",
   "metadata": {},
   "source": [
    "There is a strong feature interaction between Latitude and Longitude. To visualize this effect, we create contribution plots using the two features trees that only include Latitude and Longitude.\n",
    "\n",
    "These are similar to partial dependence plots\n",
    "https://christophm.github.io/interpretable-ml-book/pdp.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26239384",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = list(permutations(np.linspace(-3,3,200),2)) \n",
    "x_temp = pd.DataFrame(pairs,columns = ['Latitude','Longitude'])\n",
    "for i in cols:\n",
    "    if i not in ['Latitude','Longitude']:\n",
    "        x_temp[i] = 0\n",
    "x_temp = x_temp[X.columns]\n",
    "pred_all = []\n",
    "loc = 0\n",
    "for tree in tree_list:\n",
    "    if (('Longitude' in cols[tree.feature_importances_>0]) &('Latitude' in cols[tree.feature_importances_>0]) & (len(cols[tree.feature_importances_>0]) == 2)):\n",
    "        pred = tree.predict(x_temp)\n",
    "        pred_all.append(pred*sub_weights[loc])\n",
    "        \n",
    "    loc = loc + 1\n",
    "pred_all = np.sum(pred_all,axis = 0)\n",
    "\n",
    "\n",
    "df = pd.DataFrame(pairs,columns = ['Latitude','Longitude'])\n",
    "df['contribution'] = pred_all\n",
    "\n",
    "contribution = df['contribution']\n",
    "\n",
    "#Unscale the data for easier interpretation\n",
    "temp = df.drop('contribution',axis = 1)\n",
    "for i in cols:\n",
    "    if i not in ['Latitude','Longitude']:\n",
    "        temp[i] = 0\n",
    "temp = temp[X.columns]\n",
    "temp = pd.DataFrame(xTrainScaler.inverse_transform(temp), columns = X.columns)\n",
    "df = temp[['Latitude', 'Longitude']].round(3)\n",
    "df['contribution'] = contribution.round(3)\n",
    "\n",
    "df_plot = df.pivot_table(index='Latitude', columns='Longitude', values='contribution')\n",
    "sns.heatmap(df_plot , cmap = 'RdBu', fmt='.4f')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4125d3c8",
   "metadata": {},
   "source": [
    "Converting this plot to a map yields the plot below. Red indicates positive contribution to housing cost, yellow neutral, and green a reduction to housing cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23207ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "map1 = df.copy()\n",
    "map1['color'] = pd.cut(map1['contribution'], bins=3, \n",
    "                              labels=['green', 'yellow', 'red'])\n",
    "mapit = folium.Map( location=[36.7783, -119.4179], zoom_start=6 )\n",
    "for i,row in map1.iterrows():\n",
    "    folium.CircleMarker([row['Latitude'],row['Longitude']], radius = .5,color=row['color']).add_to(mapit)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a46918",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a85bba9",
   "metadata": {},
   "source": [
    "These results are consistent with the California housing market, where houses in San Francisco and Los Angeles are very expensive but housing prices drop as you move inland.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
